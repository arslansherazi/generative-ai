{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'create_openai_functions_agent' from 'langchain_experimental.agents' (/Users/arslanhaider/.local/share/virtualenvs/generative-ai-XwelIRLU/lib/python3.12/site-packages/langchain_experimental/agents/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mretrievers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdocument_compressors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LLMChainExtractor\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdocuments\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Document\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_experimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01magents\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m create_openai_functions_agent\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_experimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01magents\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01magent_toolkits\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Neo4jToolkit\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'create_openai_functions_agent' from 'langchain_experimental.agents' (/Users/arslanhaider/.local/share/virtualenvs/generative-ai-XwelIRLU/lib/python3.12/site-packages/langchain_experimental/agents/__init__.py)"
     ]
    }
   ],
   "source": [
    "from langchain_community.graphs import Neo4jGraph\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import LLMChainExtractor\n",
    "from langchain_core.documents import Document\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = Neo4jGraph(\n",
    "    url=\"bolt://localhost:7689\", username=\"neo4j\", password=\"admin_neo4j\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_data = [\n",
    "    {\"title\": \"Inception\", \"director\": \"Christopher Nolan\", \"actors\": [\"Leonardo DiCaprio\", \"Tom Hardy\"]},\n",
    "    {\"title\": \"Interstellar\", \"director\": \"Christopher Nolan\", \"actors\": [\"Matthew McConaughey\", \"Anne Hathaway\"]},\n",
    "    {\"title\": \"The Dark Knight\", \"director\": \"Christopher Nolan\", \"actors\": [\"Christian Bale\", \"Heath Ledger\"]},\n",
    "    {\"title\": \"Dunkirk\", \"director\": \"Christopher Nolan\", \"actors\": [\"Tom Hardy\", \"Harry Styles\"]},\n",
    "    {\"title\": \"The Revenant\", \"director\": \"Alejandro González Iñárritu\", \"actors\": [\"Leonardo DiCaprio\", \"Tom Hardy\"]},\n",
    "    {\"title\": \"Mad Max: Fury Road\", \"director\": \"George Miller\", \"actors\": [\"Tom Hardy\", \"Charlize Theron\"]},\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Populate Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for movie_info in movies_data:\n",
    "    title = movie_info[\"title\"]\n",
    "    director = movie_info[\"director\"]\n",
    "    actors = movie_info[\"actors\"]\n",
    "\n",
    "    # Create Movie node\n",
    "    graph.query(f\"CREATE (m:Movie {{title: '{title}'}})\")\n",
    "\n",
    "    # Create Director node and relationship\n",
    "    graph.query(f\"MERGE (d:Person {{name: '{director}'}}) CREATE (d)-[:DIRECTED]->(m)\")\n",
    "\n",
    "    # Create Actor nodes and relationships\n",
    "    for actor in actors:\n",
    "        graph.query(f\"MERGE (a:Person {{name: '{actor}'}}) CREATE (a)-[:ACTED_IN]->(m)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\n",
    "    Document(page_content=str(movie), metadata={\"title\": movie[\"title\"]})\n",
    "    for movie in movies_data\n",
    "]\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "vectorstore = FAISS.from_documents(documents, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_retriever = GraphRetriever(\n",
    "    graph=graph,\n",
    "    retrieval_query=\"\"\"\n",
    "    MATCH (p:Person)-[:ACTED_IN]->(m:Movie)\n",
    "    WHERE p.name = $personName\n",
    "    RETURN m.title AS title\n",
    "    \"\"\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0)\n",
    "compressor = LLMChainExtractor.from_llm(llm)\n",
    "compression_retriever = ContextualCompressionRetriever(base_compressor=compressor, base_retriever=vectorstore.as_retriever())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combined_retriever(query):\n",
    "    graph_results = graph_retriever.get_relevant_documents(query)\n",
    "    vector_results = compression_retriever.get_relevant_documents(query)\n",
    "    return graph_results + vector_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_prompt = PromptTemplate(\n",
    "    template=\"\"\"Use the context below to answer the question.\n",
    "\n",
    "    Context: {context}\n",
    "\n",
    "    Question: {question}\"\"\",\n",
    "    input_variables=[\"context\", \"question\"],\n",
    ")\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=ChatOpenAI(),\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=combined_retriever,\n",
    "    chain_type_kwargs={\"prompt\": qa_prompt},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example Query 1\n",
    "query = \"What movies did actors who worked with Christopher Nolan also star in?\"\n",
    "result = qa_chain.run(query)\n",
    "print(result)\n",
    "\n",
    "#Example Query 2\n",
    "query = \"Tell me about the movie Inception\"\n",
    "result = qa_chain.run(query)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Neo4j population example.\n",
    "\"\"\"\n",
    "#Neo4j population example.\n",
    "#This is an example of cypher code, that would populate the graph.\n",
    "#You would need to adapt it to your specific data.\n",
    "#LOAD CSV WITH HEADERS FROM \"file:///movies.csv\" AS row\n",
    "#CREATE (:Movie {title: row.title})\n",
    "\n",
    "#LOAD CSV WITH HEADERS FROM \"file:///actors.csv\" AS row\n",
    "#CREATE (:Person {name: row.name})\n",
    "\n",
    "#LOAD CSV WITH HEADERS FROM \"file:///directors.csv\" AS row\n",
    "#CREATE (:Person {name: row.name})\n",
    "\n",
    "#LOAD CSV WITH HEADERS FROM \"file:///acted_in.csv\" AS row\n",
    "#MATCH (p:Person {name: row.actor})\n",
    "#MATCH (m:Movie {title: row.movie})\n",
    "#CREATE (p)-[:ACTED_IN]->(m)\n",
    "\n",
    "#LOAD CSV WITH HEADERS FROM \"file:///directed_by.csv\" AS row\n",
    "#MATCH (p:Person {name: row.director})\n",
    "#MATCH (m:Movie {title: row.movie})\n",
    "#CREATE (p)-[:DIRECTED_BY]->(m)\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "generative-ai-XwelIRLU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
