{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Great Wall of China\n",
      "2. Petra, Jordan\n",
      "3. Christ the Redeemer, Brazil\n",
      "4. Machu Picchu, Peru\n",
      "5. Chichen Itza, Mexico\n",
      "6. Colosseum, Italy\n",
      "7. Taj Mahal, India\n",
      "8. Great Pyramid of Giza, Egypt\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema import HumanMessage\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "\n",
    "messages = [\n",
    "    HumanMessage(content=\"List 8 wonders of the word\")\n",
    "]\n",
    "\n",
    "result = llm.invoke(messages)\n",
    "\n",
    "wonders_list = result.content.split(\"\\n\")\n",
    "\n",
    "for wonder in wonders_list:\n",
    "    print(wonder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Streaming and Batching\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1\n",
      ".\n",
      " Great\n",
      " Wall\n",
      " of\n",
      " China\n",
      "\n",
      "\n",
      "2\n",
      ".\n",
      " Petra\n",
      ",\n",
      " Jordan\n",
      "\n",
      "\n",
      "3\n",
      ".\n",
      " Christ\n",
      " the\n",
      " Rede\n",
      "emer\n",
      " statue\n",
      " in\n",
      " Rio\n",
      " de\n",
      " Janeiro\n",
      ",\n",
      " Brazil\n",
      "\n",
      "\n",
      "4\n",
      ".\n",
      " Mach\n",
      "u\n",
      " Pic\n",
      "chu\n",
      ",\n",
      " Peru\n",
      "\n",
      "\n",
      "5\n",
      ".\n",
      " Taj\n",
      " Mah\n",
      "al\n",
      ",\n",
      " India\n",
      "\n",
      "\n",
      "6\n",
      ".\n",
      " Col\n",
      "os\n",
      "se\n",
      "um\n",
      " in\n",
      " Rome\n",
      ",\n",
      " Italy\n",
      "\n",
      "\n",
      "7\n",
      ".\n",
      " Ch\n",
      "ichen\n",
      " It\n",
      "za\n",
      ",\n",
      " Mexico\n",
      "\n",
      "\n",
      "8\n",
      ".\n",
      " Pyramid\n",
      " of\n",
      " G\n",
      "iza\n",
      ",\n",
      " Egypt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for chunk in llm.stream(\"8 Wonders of World\"):\n",
    "    print(chunk.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 + 2 = 4\n",
      "58.68\n"
     ]
    }
   ],
   "source": [
    "result = llm.batch(\n",
    "    [\n",
    "        \"What's 2 +2 ?\",\n",
    "        \"What's 34.9 + 23.78?\"\n",
    "    ]\n",
    ")\n",
    "for _result in result:\n",
    "    print(_result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## System & Human Message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I am associated with the cricket bat manufacturer, MRF.'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.schema import SystemMessage\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are Virat Kohli\"),\n",
    "    HumanMessage(content=\"Which crickrt bat manufacturer you are associated with?\")\n",
    "]\n",
    "\n",
    "result = llm.invoke(messages)\n",
    "result.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Why did the robot go on a diet?\\n\\nBecause he had a byte problem!'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "    \"tell me a {objective} joke about {content}\"\n",
    ")\n",
    "\n",
    "filled_prompt = prompt_template.format(objective=\"funny\", content=\"robots\")\n",
    "\n",
    "response = llm.invoke(filled_prompt)\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chat Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a helpful AI Mathematics teacher bot. Your name is {name}\n",
      "Hello, How are you doing?\n",
      "I'm doing well, thanks!\n",
      "{math_problem}\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage\n",
    "\n",
    "# Defining a chat template with various roles\n",
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessage(content=\"You are a helpful AI Mathematics teacher bot. Your name is {name}\"),\n",
    "        HumanMessage(content=\"Hello, How are you doing?\"),\n",
    "        AIMessage(content=\"I'm doing well, thanks!\"),\n",
    "        HumanMessage(content=\"{math_problem}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "math_problem = input(\"Enter Math problem:\")\n",
    "\n",
    "formatted_messages = chat_template.format_messages(name=\"Bob\", math_problem=math_problem)\n",
    "\n",
    "for message in formatted_messages:\n",
    "    print(message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output Parsers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Json Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'birth_place': {'Elon Musk': 'Pretoria, South Africa',\n",
       "  'Bill Gates': 'Seattle, Washington, United States'},\n",
       " 'birth_date': {'Elon Musk': 'June 28, 1971',\n",
       "  'Bill Gates': 'October 28, 1955'}}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.output_parsers.json import SimpleJsonOutputParser\n",
    "\n",
    "json_parser = SimpleJsonOutputParser()\n",
    "\n",
    "template = \"\"\"\n",
    "Answer the user's question:\n",
    "{question}\n",
    "Return the answer as a JSON object with keys 'birth_place' and 'birth_date'.\n",
    "\"\"\"\n",
    "\n",
    "json_prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "json_chain = json_prompt | llm | json_parser\n",
    "\n",
    "input_data = {\"question\": \"When and where were Elon Musk and Bill Gates born?\"}\n",
    "\n",
    "output = json_chain.invoke(input_data)\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSV Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Afghanistan',\n",
       " 'Kabul',\n",
       " '1919\\nBahrain',\n",
       " 'Manama',\n",
       " '1971\\nBangladesh',\n",
       " 'Dhaka',\n",
       " '1971\\nBhutan',\n",
       " 'Thimphu',\n",
       " '1949\\nBrunei',\n",
       " 'Bandar Seri Begawan',\n",
       " '1984\\nCambodia',\n",
       " 'Phnom Penh',\n",
       " '1953\\nChina',\n",
       " 'Beijing',\n",
       " '1949\\nIndia',\n",
       " 'New Delhi',\n",
       " '1947\\nIndonesia',\n",
       " 'Jakarta',\n",
       " '1945\\nIran',\n",
       " 'Tehran',\n",
       " '1935\\nIraq',\n",
       " 'Baghdad',\n",
       " '1932\\nIsrael',\n",
       " 'Jerusalem',\n",
       " '1948\\nJapan',\n",
       " 'Tokyo',\n",
       " '660 BC\\nJordan',\n",
       " 'Amman',\n",
       " '1946\\nKazakhstan',\n",
       " 'Nur-Sultan',\n",
       " '1991\\nKuwait',\n",
       " 'Kuwait City',\n",
       " '1961\\nKyrgyzstan',\n",
       " 'Bishkek',\n",
       " '1991\\nLaos',\n",
       " 'Vientiane',\n",
       " '1949\\nLebanon',\n",
       " 'Beirut',\n",
       " '1943\\nMalaysia',\n",
       " 'Kuala Lumpur',\n",
       " '1957\\nMaldives',\n",
       " 'Malé',\n",
       " '1965\\nMongolia',\n",
       " 'Ulaanbaatar',\n",
       " '1921\\nMyanmar',\n",
       " 'Naypyidaw',\n",
       " '1948\\nNepal',\n",
       " 'Kathmandu',\n",
       " '1768\\nNorth Korea',\n",
       " 'Pyongyang',\n",
       " '1948\\nOman',\n",
       " 'Muscat',\n",
       " '1650\\nPakistan',\n",
       " 'Islamabad',\n",
       " '1947\\nPalestine',\n",
       " 'East Jerusalem',\n",
       " '1988\\nPhilippines',\n",
       " 'Manila',\n",
       " '1898\\nQatar',\n",
       " 'Doha',\n",
       " '1971\\nSaudi Arabia',\n",
       " 'Riyadh',\n",
       " '1932\\nSingapore',\n",
       " 'Singapore',\n",
       " '1965\\nSouth Korea',\n",
       " 'Seoul',\n",
       " '1948\\nSri Lanka',\n",
       " 'Colombo',\n",
       " '1948\\nSyria',\n",
       " 'Damascus',\n",
       " '1946\\nTajikistan',\n",
       " 'Dushanbe',\n",
       " '1991\\nThailand',\n",
       " 'Bangkok',\n",
       " '1238\\nTimor-Leste',\n",
       " 'Dili',\n",
       " '2002\\nTurkey',\n",
       " 'Ankara',\n",
       " '1923\\nTurkmenistan',\n",
       " 'Ashgabat',\n",
       " '1991\\nUnited Arab Emirates',\n",
       " 'Abu Dhabi',\n",
       " '1971\\nUzbekistan',\n",
       " 'Tashkent',\n",
       " '1991\\nVietnam',\n",
       " 'Hanoi',\n",
       " '1945\\nYemen',\n",
       " 'Sanaa',\n",
       " '1918']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.output_parsers import CommaSeparatedListOutputParser\n",
    "\n",
    "csv_parser = CommaSeparatedListOutputParser()\n",
    "\n",
    "template = \"\"\"\n",
    "Answer the user's question:\n",
    "{question}\n",
    "Return the answer as a comma-separated list with the format: \"Country, Capital, Independence Date\".\n",
    "Only include countries in Asia.\n",
    "\"\"\"\n",
    "\n",
    "csv_prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "csv_chain = csv_prompt | llm | csv_parser\n",
    "\n",
    "input_data = {\"question\": \"Give details of countries in Aisa\"}\n",
    "\n",
    "output = csv_chain.invoke(input_data)\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Welcome to Smallpdf',\n",
       " 'Digital Documents—All In One Place',\n",
       " 'Access Files Anytime, Anywhere Enhance Documents in One Click ',\n",
       " 'Collaborate With Others With the new Smallpdf experience, you can ',\n",
       " 'freely upload, organize, and share digital ',\n",
       " 'documents. When you enable the ‘Storage’ ',\n",
       " 'option, we’ll also store all processed files here. ',\n",
       " 'You can access files stored on Smallpdf from ',\n",
       " 'your computer, phone, or tablet. We’ll also ',\n",
       " 'sync files from the Smallpdf Mobile App to our ',\n",
       " 'online portalWhen you right-click on a file, we’ll present ',\n",
       " 'you with an array of options to convert, ',\n",
       " 'compress, or modify it. ',\n",
       " 'Forget mundane administrative tasks. With ',\n",
       " 'Smallpdf, you can request e-signatures, send ',\n",
       " 'large files, or even enable the Smallpdf G Suite ',\n",
       " 'App for your entire organization. Ready to take document management to the next level?']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(\"/home/arslanhaider/ahs-data/test-pdf.pdf\")\n",
    "\n",
    "pages = loader.load_and_split()\n",
    "\n",
    "pages[0].page_content.split(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI should first read the tasks for today from a file and then check the weather to see if I can go jogging.\n",
      "Action: read_tasks_from_file\n",
      "Action Input: today\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m[{'title': 'Buy groceries', 'tags': ['shopping']}, {'title': 'Jogging', 'tags': ['outdoor', 'exercise']}, {'title': 'Team meeting', 'tags': ['work']}]\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI need to check the weather to see if I can go jogging and then schedule my team meeting.\n",
      "Action: check_weather\n",
      "Action Input: today\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m{'queryCost': 1, 'latitude': 51.5064, 'longitude': -0.12721, 'resolvedAddress': 'London, England, United Kingdom', 'address': 'London,UK', 'timezone': 'Europe/London', 'tzoffset': 1.0, 'description': 'Similar temperatures continuing with no rain expected.', 'days': [{'datetime': '2024-09-04', 'datetimeEpoch': 1725404400, 'tempmax': 66.8, 'tempmin': 56.4, 'temp': 61.9, 'feelslikemax': 66.8, 'feelslikemin': 56.4, 'feelslike': 61.9, 'dew': 53.0, 'humidity': 73.4, 'precip': 0.106, 'precipprob': 80.6, 'precipcover': 16.67, 'preciptype': ['rain'], 'snow': 0.0, 'snowdepth': 0.0, 'windgust': 16.6, 'windspeed': 6.9, 'winddir': 332.0, 'pressure': 1016.3, 'cloudcover': 76.0, 'visibility': 8.2, 'solarradiation': 109.6, 'solarenergy': 9.2, 'uvindex': 5.0, 'severerisk': 10.0, 'sunrise': '06:18:29', 'sunriseEpoch': 1725427109, 'sunset': '19:39:20', 'sunsetEpoch': 1725475160, 'moonphase': 0.05, 'conditions': 'Rain, Partially cloudy', 'description': 'Partly cloudy throughout the day with late afternoon rain.', 'icon': 'rain', 'stations': ['EGWU', 'EGLL', 'D5621', 'EGLC'], 'source': 'comb', 'hours': [{'datetime': '00:00:00', 'datetimeEpoch': 1725404400, 'temp': 63.6, 'feelslike': 63.6, 'humidity': 75.42, 'dew': 55.7, 'precip': 0.0, 'precipprob': 0.0, 'snow': 0.0, 'snowdepth': 0.0, 'preciptype': None, 'windgust': 4.9, 'windspeed': 6.9, 'winddir': 289.0, 'pressure': 1015.2, 'visibility': 6.2, 'cloudcover': 100.0, 'solarradiation': 0.0, 'solarenergy': 0.0, 'uvindex': 0.0, 'severerisk': 10.0, 'conditions': 'Overcast', 'icon': 'cloudy', 'stations': ['EGWU', 'EGLL', 'D5621', 'EGLC'], 'source': 'obs'}, {'datetime': '01:00:00', 'datetimeEpoch': 1725408000, 'temp': 62.9, 'feelslike': 62.9, 'humidity': 77.31, 'dew': 55.7, 'precip': 0.0, 'precipprob': 0.0, 'snow': 0.0, 'snowdepth': 0.0, 'preciptype': None, 'windgust': 6.0, 'windspeed': 4.5, 'winddir': 280.0, 'pressure': 1015.2, 'visibility': 6.2, 'cloudcover': 94.5, 'solarradiation': 0.0, 'solarenergy': 0.0, 'uvindex': 0.0, 'severerisk': 10.0, 'conditions': 'Overcast', 'icon': 'cloudy', 'stations': ['EGWU', 'EGLL', 'D5621', 'EGLC'], 'source': 'obs'}, {'datetime': '02:00:00', 'datetimeEpoch': 1725411600, 'temp': 62.5, 'feelslike': 62.5, 'humidity': 75.32, 'dew': 54.6, 'precip': 0.0, 'precipprob': 0.0, 'snow': 0.0, 'snowdepth': 0.0, 'preciptype': None, 'windgust': 8.1, 'windspeed': 3.9, 'winddir': 288.0, 'pressure': 1015.2, 'visibility': 6.2, 'cloudcover': 97.5, 'solarradiation': 0.0, 'solarenergy': 0.0, 'uvindex': 0.0, 'severerisk': 10.0, 'conditions': 'Overcast', 'icon': 'cloudy', 'stations': ['EGWU', 'EGLL', 'D5621', 'EGLC'], 'source': 'obs'}, {'datetime': '03:00:00', 'datetimeEpoch': 1725415200, 'temp': 61.8, 'feelslike': 61.8, 'humidity': 80.35, 'dew': 55.7, 'precip': 0.0, 'precipprob': 0.0, 'snow': 0.0, 'snowdepth': 0.0, 'preciptype': None, 'windgust': 7.8, 'windspeed': 4.9, 'winddir': 248.0, 'pressure': 1015.4, 'visibility': 6.2, 'cloudcover': 92.7, 'solarradiation': 0.0, 'solarenergy': 0.0, 'uvindex': 0.0, 'severerisk': 10.0, 'conditions': 'Overcast', 'icon': 'cloudy', 'stations': ['EGWU', 'EGLL', 'D5621', 'EGLC'], 'source': 'obs'}, {'datetime': '04:00:00', 'datetimeEpoch': 1725418800, 'temp': 59.7, 'feelslike': 59.7, 'humidity': 81.15, 'dew': 53.9, 'precip': 0.0, 'precipprob': 0.0, 'snow': 0.0, 'snowdepth': 0.0, 'preciptype': None, 'windgust': 6.7, 'windspeed': 6.1, 'winddir': 266.0, 'pressure': 1016.0, 'visibility': 6.1, 'cloudcover': 41.3, 'solarradiation': 0.0, 'solarenergy': 0.0, 'uvindex': 0.0, 'severerisk': 10.0, 'conditions': 'Partially cloudy', 'icon': 'partly-cloudy-night', 'stations': ['EGWU', 'EGLL', 'D5621', 'EGLC'], 'source': 'obs'}, {'datetime': '05:00:00', 'datetimeEpoch': 1725422400, 'temp': 58.2, 'feelslike': 58.2, 'humidity': 81.21, 'dew': 52.5, 'precip': 0.0, 'precipprob': 0.0, 'snow': 0.0, 'snowdepth': 0.0, 'preciptype': None, 'windgust': 6.7, 'windspeed': 4.7, 'winddir': 290.0, 'pressure': 1016.0, 'visibility': 6.2, 'cloudcover': 23.7, 'solarradiation': 0.0, 'solarenergy': 0.0, 'uvindex': 0.0, 'severerisk': 10.0, 'conditions': 'Partially cloudy', 'icon': 'partly-cloudy-night', 'stations': ['EGWU', 'EGLL', 'D5621', 'EGLC'], 'source': 'obs'}, {'datetime': '06:00:00', 'datetimeEpoch': 1725426000, 'temp': 57.5, 'feelslike': 57.5, 'humidity': 80.99, 'dew': 51.7, 'precip': 0.0, 'precipprob': 0.0, 'snow': 0.0, 'snowdepth': 0.0, 'preciptype': None, 'windgust': 5.8, 'windspeed': 4.9, 'winddir': 296.0, 'pressure': 1016.0, 'visibility': 6.2, 'cloudcover': 28.1, 'solarradiation': 0.0, 'solarenergy': 0.0, 'uvindex': 0.0, 'severerisk': 10.0, 'conditions': 'Partially cloudy', 'icon': 'partly-cloudy-night', 'stations': ['EGWU', 'EGLL', 'D5621', 'EGLC'], 'source': 'obs'}, {'datetime': '07:00:00', 'datetimeEpoch': 1725429600, 'temp': 56.4, 'feelslike': 56.4, 'humidity': 82.22, 'dew': 51.0, 'precip': 0.0, 'precipprob': 0.0, 'snow': 0.0, 'snowdepth': 0.0, 'preciptype': None, 'windgust': 4.3, 'windspeed': 4.4, 'winddir': 298.0, 'pressure': 1016.2, 'visibility': 6.2, 'cloudcover': 50.0, 'solarradiation': 33.0, 'solarenergy': 0.1, 'uvindex': 0.0, 'severerisk': 10.0, 'conditions': 'Partially cloudy', 'icon': 'partly-cloudy-day', 'stations': ['EGWU', 'EGLL', 'D5621', 'EGLC'], 'source': 'obs'}, {'datetime': '08:00:00', 'datetimeEpoch': 1725433200, 'temp': 57.4, 'feelslike': 57.4, 'humidity': 81.15, 'dew': 51.7, 'precip': 0.0, 'precipprob': 0.0, 'snow': 0.0, 'snowdepth': 0.0, 'preciptype': None, 'windgust': 5.8, 'windspeed': 4.2, 'winddir': 314.0, 'pressure': 1017.0, 'visibility': 6.2, 'cloudcover': 81.2, 'solarradiation': 82.0, 'solarenergy': 0.3, 'uvindex': 1.0, 'severerisk': 10.0, 'conditions': 'Partially cloudy', 'icon': 'partly-cloudy-day', 'stations': ['EGWU', 'EGLL', 'D5621', 'EGLC'], 'source': 'obs'}, {'datetime': '09:00:00', 'datetimeEpoch': 1725436800, 'temp': 57.8, 'feelslike': 57.8, 'humidity': 81.18, 'dew': 52.1, 'precip': 0.0, 'precipprob': 0.0, 'snow': 0.0, 'snowdepth': 0.0, 'preciptype': None, 'windgust': 6.7, 'windspeed': 4.2, 'winddir': 339.0, 'pressure': 1017.0, 'visibility': 6.2, 'cloudcover': 70.5, 'solarradiation': 458.0, 'solarenergy': 1.6, 'uvindex': 5.0, 'severerisk': 10.0, 'conditions': 'Partially cloudy', 'icon': 'partly-cloudy-day', 'stations': ['EGWU', 'EGLL', 'D5621', 'EGLC'], 'source': 'obs'}, {'datetime': '10:00:00', 'datetimeEpoch': 1725440400, 'temp': 62.9, 'feelslike': 62.9, 'humidity': 68.74, 'dew': 52.5, 'precip': 0.0, 'precipprob': 0.0, 'snow': 0.0, 'snowdepth': 0.0, 'preciptype': None, 'windgust': 6.5, 'windspeed': 4.3, 'winddir': 355.0, 'pressure': 1017.0, 'visibility': 6.2, 'cloudcover': 78.2, 'solarradiation': 302.0, 'solarenergy': 1.1, 'uvindex': 3.0, 'severerisk': 10.0, 'conditions': 'Partially cloudy', 'icon': 'partly-cloudy-day', 'stations': ['EGWU', 'EGLL', 'D5621', 'EGLC'], 'source': 'obs'}, {'datetime': '11:00:00', 'datetimeEpoch': 1725444000, 'temp': 63.9, 'feelslike': 63.9, 'humidity': 66.16, 'dew': 52.4, 'precip': 0.0, 'precipprob': 0.0, 'snow': 0.0, 'snowdepth': 0.0, 'preciptype': None, 'windgust': 7.8, 'windspeed': 6.5, 'winddir': 360.0, 'pressure': 1017.0, 'visibility': 6.2, 'cloudcover': 56.9, 'solarradiation': 418.0, 'solarenergy': 1.5, 'uvindex': 4.0, 'severerisk': 10.0, 'conditions': 'Partially cloudy', 'icon': 'partly-cloudy-day', 'stations': ['EGWU', 'EGLL', 'D5621', 'EGLC'], 'source': 'obs'}, {'datetime': '12:00:00', 'datetimeEpoch': 1725447600, 'temp': 63.9, 'feelslike': 63.9, 'humidity': 64.47, 'dew': 51.7, 'precip': 0.0, 'precipprob': 0.0, 'snow': 0.0, 'snowdepth': 0.0, 'preciptype': ['rain'], 'windgust': 7.6, 'windspeed': 4.3, 'winddir': 321.0, 'pressure': 1017.2, 'visibility': 6.2, 'cloudcover': 50.0, 'solarradiation': 343.0, 'solarenergy': 1.2, 'uvindex': 3.0, 'severerisk': 10.0, 'conditions': 'Partially cloudy', 'icon': 'partly-cloudy-day', 'stations': ['EGWU', 'EGLL', 'D5621', 'EGLC'], 'source': 'obs'}, {'datetime': '13:00:00', 'datetimeEpoch': 1725451200, 'temp': 65.4, 'feelslike': 65.4, 'humidity': 60.5, 'dew': 51.4, 'precip': 0.0, 'precipprob': 0.0, 'snow': 0.0, 'snowdepth': 0.0, 'preciptype': ['rain'], 'windgust': 7.4, 'windspeed': 4.9, 'winddir': 356.0, 'pressure': 1017.2, 'visibility': 6.2, 'cloudcover': 58.0, 'solarradiation': 290.0, 'solarenergy': 1.0, 'uvindex': 3.0, 'severerisk': 10.0, 'conditions': 'Partially cloudy', 'icon': 'partly-cloudy-day', 'stations': ['EGWU', 'EGLL', 'D5621', 'EGLC'], 'source': 'obs'}, {'datetime': '14:00:00', 'datetimeEpoch': 1725454800, 'temp': 65.8, 'feelslike': 65.8, 'humidity': 61.28, 'dew': 52.1, 'precip': 0.0, 'precipprob': 0.0, 'snow': 0.0, 'snowdepth': 0.0, 'preciptype': ['rain'], 'windgust': 7.4, 'windspeed': 6.8, 'winddir': 316.0, 'pressure': 1017.0, 'visibility': 6.2, 'cloudcover': 81.1, 'solarradiation': 152.0, 'solarenergy': 0.5, 'uvindex': 2.0, 'severerisk': 10.0, 'conditions': 'Partially cloudy', 'icon': 'partly-cloudy-day', 'stations': ['EGWU', 'EGLL', 'D5621', 'EGLC'], 'source': 'obs'}, {'datetime': '15:00:00', 'datetimeEpoch': 1725458400, 'temp': 66.4, 'feelslike': 66.4, 'humidity': 56.87, 'dew': 50.7, 'precip': 0.0, 'precipprob': 0.0, 'snow': 0.0, 'snowdepth': 0.0, 'preciptype': ['rain'], 'windgust': 6.0, 'windspeed': 6.7, 'winddir': 340.0, 'pressure': 1017.0, 'visibility': 6.2, 'cloudcover': 42.8, 'solarradiation': 150.0, 'solarenergy': 0.5, 'uvindex': 2.0, 'severerisk': 10.0, 'conditions': 'Partially cloudy', 'icon': 'partly-cloudy-day', 'stations': ['EGWU', 'EGLL', 'D5621', 'EGLC'], 'source': 'obs'}, {'datetime': '16:00:00', 'datetimeEpoch': 1725462000, 'temp': 65.0, 'feelslike': 65.0, 'humidity': 57.37, 'dew': 49.6, 'precip': 0.0, 'precipprob': 0.0, 'snow': 0.0, 'snowdepth': 0.0, 'preciptype': ['rain'], 'windgust': 2.9, 'windspeed': 6.5, 'winddir': 11.0, 'pressure': 1016.8, 'visibility': 6.2, 'cloudcover': 88.0, 'solarradiation': 97.0, 'solarenergy': 0.3, 'uvindex': 1.0, 'severerisk': 10.0, 'conditions': 'Partially cloudy', 'icon': 'partly-cloudy-day', 'stations': ['EGWU', 'EGLL', 'D5621', 'EGLC'], 'source': 'obs'}, {'datetime': '17:00:00', 'datetimeEpoch': 1725465600, 'temp': 66.8, 'feelslike': 66.8, 'humidity': 54.52, 'dew': 49.9, 'precip': 0.0, 'precipprob': 48.4, 'snow': 0.0, 'snowdepth': 0.0, 'preciptype': ['rain'], 'windgust': 12.5, 'windspeed': 5.1, 'winddir': 341.4, 'pressure': 1016.0, 'visibility': 15.0, 'cloudcover': 99.2, 'solarradiation': 139.0, 'solarenergy': 0.5, 'uvindex': 1.0, 'severerisk': 10.0, 'conditions': 'Rain, Overcast', 'icon': 'rain', 'stations': None, 'source': 'fcst'}, {'datetime': '18:00:00', 'datetimeEpoch': 1725469200, 'temp': 64.3, 'feelslike': 64.3, 'humidity': 66.63, 'dew': 53.0, 'precip': 0.0, 'precipprob': 48.4, 'snow': 0.0, 'snowdepth': 0.0, 'preciptype': ['rain'], 'windgust': 16.6, 'windspeed': 6.9, 'winddir': 352.6, 'pressure': 1016.0, 'visibility': 15.0, 'cloudcover': 92.5, 'solarradiation': 120.0, 'solarenergy': 0.4, 'uvindex': 1.0, 'severerisk': 10.0, 'conditions': 'Rain, Overcast', 'icon': 'rain', 'stations': None, 'source': 'fcst'}, {'datetime': '19:00:00', 'datetimeEpoch': 1725472800, 'temp': 62.7, 'feelslike': 62.7, 'humidity': 72.41, 'dew': 53.7, 'precip': 0.004, 'precipprob': 48.4, 'snow': 0.0, 'snowdepth': 0.0, 'preciptype': ['rain'], 'windgust': 16.6, 'windspeed': 6.3, 'winddir': 18.7, 'pressure': 1016.0, 'visibility': 12.4, 'cloudcover': 98.1, 'solarradiation': 46.0, 'solarenergy': 0.2, 'uvindex': 0.0, 'severerisk': 10.0, 'conditions': 'Rain, Overcast', 'icon': 'rain', 'stations': None, 'source': 'fcst'}, {'datetime': '20:00:00', 'datetimeEpoch': 1725476400, 'temp': 61.2, 'feelslike': 61.2, 'humidity': 78.73, 'dew': 54.6, 'precip': 0.012, 'precipprob': 80.6, 'snow': 0.0, 'snowdepth': 0.0, 'preciptype': ['rain'], 'windgust': 15.2, 'windspeed': 5.1, 'winddir': 33.3, 'pressure': 1016.0, 'visibility': 15.0, 'cloudcover': 99.4, 'solarradiation': 0.0, 'solarenergy': 0.0, 'uvindex': 0.0, 'severerisk': 10.0, 'conditions': 'Rain, Overcast', 'icon': 'rain', 'stations': None, 'source': 'fcst'}, {'datetime': '21:00:00', 'datetimeEpoch': 1725480000, 'temp': 59.8, 'feelslike': 59.8, 'humidity': 86.18, 'dew': 55.7, 'precip': 0.059, 'precipprob': 80.6, 'snow': 0.0, 'snowdepth': 0.0, 'preciptype': ['rain'], 'windgust': 12.3, 'windspeed': 3.6, 'winddir': 25.4, 'pressure': 1016.0, 'visibility': 14.7, 'cloudcover': 99.7, 'solarradiation': 0.0, 'solarenergy': 0.0, 'uvindex': 0.0, 'severerisk': 10.0, 'conditions': 'Rain, Overcast', 'icon': 'rain', 'stations': None, 'source': 'fcst'}, {'datetime': '22:00:00', 'datetimeEpoch': 1725483600, 'temp': 59.6, 'feelslike': 59.6, 'humidity': 86.17, 'dew': 55.5, 'precip': 0.031, 'precipprob': 80.6, 'snow': 0.0, 'snowdepth': 0.0, 'preciptype': ['rain'], 'windgust': 9.6, 'windspeed': 4.0, 'winddir': 26.0, 'pressure': 1016.0, 'visibility': 8.1, 'cloudcover': 100.0, 'solarradiation': 0.0, 'solarenergy': 0.0, 'uvindex': 0.0, 'severerisk': 10.0, 'conditions': 'Rain, Overcast', 'icon': 'rain', 'stations': None, 'source': 'fcst'}, {'datetime': '23:00:00', 'datetimeEpoch': 1725487200, 'temp': 59.4, 'feelslike': 59.4, 'humidity': 85.59, 'dew': 55.1, 'precip': 0.0, 'precipprob': 80.6, 'snow': 0.0, 'snowdepth': 0.0, 'preciptype': ['rain'], 'windgust': 9.4, 'windspeed': 3.6, 'winddir': 36.8, 'pressure': 1016.0, 'visibility': 12.1, 'cloudcover': 100.0, 'solarradiation': 0.0, 'solarenergy': 0.0, 'uvindex': 0.0, 'severerisk': 10.0, 'conditions': 'Rain, Overcast', 'icon': 'rain', 'stations': None, 'source': 'fcst'}]}], 'alerts': [{'event': 'Yellow rain warning', 'headline': 'Some parts missing the worst, but heavy rain becomes more extensive Wednesday night and especially Thursday,  with some flooding', 'ends': '2024-09-05T23:45:00', 'endsEpoch': 1725576300, 'onset': '2024-09-04T21:00:00', 'onsetEpoch': 1725480000, 'id': '2.49.0.0.826.0.GB_240904075503_52e45268.v2.0.R', 'language': 'en', 'link': 'https://www.metoffice.gov.uk/weather/warnings-and-advice/uk-warnings', 'description': 'Information on update: The warning period has been extended until the close of Thursday. The area has been expanded westwards but the northern and northeastern extent slightly reduced.  Wording changed to suggest that impacts will start off mostly low overnight, before potentially increasing later Thursday. Not all areas will be affected, but scattered heavy showers on Wednesday night are expected to merge into longer spells of heavy, perhaps thundery rain overnight and through Thursday. \\n\\nWhere heavy downpours occur, 20-40 mm are possible within an hour or two. Over a longer period a few places could see more than 50-60 mm, possibly even as much as 80 to 100 mm if repeated batches of heavy rain affect the same locations - this perhaps more likely during the second half of Thursday.  \\n\\nWhat should I do? \\n\\nConsider if your location is at risk of flash flooding. If so, consider preparing a flood plan and an emergency flood kit. \\n \\nGive yourself the best chance of avoiding delays by checking road conditions if driving, or bus and train timetables, amending your travel plans if necessary. \\n\\nBe prepared for weather warnings to change: the Met Office recommends staying up to date with the weather forecast in your area. For further details see https://www.metoffice.gov.uk/weather/warnings-and-advice/uk-warnings'}], 'stations': {'EGWU': {'distance': 20850.0, 'latitude': 51.55, 'longitude': -0.42, 'useCount': 0, 'id': 'EGWU', 'name': 'EGWU', 'quality': 50, 'contribution': 0.0}, 'EGLC': {'distance': 12300.0, 'latitude': 51.5, 'longitude': 0.05, 'useCount': 0, 'id': 'EGLC', 'name': 'EGLC', 'quality': 50, 'contribution': 0.0}, 'EGLL': {'distance': 22564.0, 'latitude': 51.48, 'longitude': -0.45, 'useCount': 0, 'id': 'EGLL', 'name': 'EGLL', 'quality': 50, 'contribution': 0.0}, 'D5621': {'distance': 11192.0, 'latitude': 51.535, 'longitude': 0.028, 'useCount': 0, 'id': 'D5621', 'name': 'DW5621 Upton Park UK', 'quality': 0, 'contribution': 0.0}, 'F6665': {'distance': 14583.0, 'latitude': 51.437, 'longitude': 0.051, 'useCount': 0, 'id': 'F6665', 'name': 'FW6665 Mottingham UK', 'quality': 0, 'contribution': 0.0}}, 'currentConditions': {'datetime': '15:54:00', 'datetimeEpoch': 1725461640, 'temp': 65.4, 'feelslike': 65.4, 'humidity': 62.5, 'dew': 52.3, 'precip': 0.0, 'precipprob': 0.0, 'snow': 0.0, 'snowdepth': 0.0, 'preciptype': None, 'windgust': 4.9, 'windspeed': 3.2, 'winddir': 324.0, 'pressure': 1017.0, 'visibility': 6.2, 'cloudcover': 88.0, 'solarradiation': 97.0, 'solarenergy': 0.3, 'uvindex': 1.0, 'conditions': 'Partially cloudy', 'icon': 'partly-cloudy-day', 'stations': ['D5621', 'F6665', 'EGLC'], 'source': 'obs', 'sunrise': '06:18:29', 'sunriseEpoch': 1725427109, 'sunset': '19:39:20', 'sunsetEpoch': 1725475160, 'moonphase': 0.05}}\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now need to schedule the team meeting.\n",
      "Action: add_to_calendar\n",
      "Action Input: {'title': 'Team meeting', 'tags': ['work'], 'date': 'today', 'time': '15:00'}\u001b[0mAdding task to calendar: {'title': 'Team meeting', 'tags': ['work'], 'date': 'today', 'time': '15:00'}\n",
      "\n",
      "Observation: \u001b[38;5;200m\u001b[1;3mTask {'title': 'Team meeting', 'tags': ['work'], 'date': 'today', 'time': '15:00'} added to calendar.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer\n",
      "Final Answer: Tasks for today have been managed. I can go jogging and the team meeting has been scheduled for today at 3:00 PM.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': 'Manage my tasks for today. Check if I can go jogging, and schedule my team meeting.', 'output': 'Tasks for today have been managed. I can go jogging and the team meeting has been scheduled for today at 3:00 PM.'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "import requests\n",
    "from langchain.agents import initialize_agent, Tool\n",
    "\n",
    "# Define tools as functions\n",
    "def read_tasks_from_file(input):\n",
    "    with open('tasks.json', 'r') as file:\n",
    "        tasks = json.load(file)\n",
    "    return tasks\n",
    "\n",
    "def check_weather(date):\n",
    "    response = requests.get(f\"https://weather.visualcrossing.com/VisualCrossingWebServices/rest/services/timeline/London,UK/{datetime.now().strftime('%Y-%m-%d')}?key={os.getenv('WEATHER_API_KEY')}\")\n",
    "    return response.json()\n",
    "\n",
    "def add_to_calendar(task):\n",
    "    print(f\"Adding task to calendar: {task}\")\n",
    "    return f\"Task {task} added to calendar.\"\n",
    "\n",
    "# Define the tools for the agent\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"read_tasks_from_file\",\n",
    "        func=read_tasks_from_file,\n",
    "        description=\"Reads tasks from a local JSON file\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"check_weather\",\n",
    "        func=check_weather,\n",
    "        description=\"Checks the weather forecast for a given date\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"add_to_calendar\",\n",
    "        func=add_to_calendar,\n",
    "        description=\"Adds a task to the calendar\"\n",
    "    )\n",
    "]\n",
    "\n",
    "agent = initialize_agent(tools, llm, agent=\"zero-shot-react-description\", verbose=True)\n",
    "\n",
    "\n",
    "sample_tasks = [\n",
    "    {\"title\": \"Buy groceries\", \"tags\": [\"shopping\"]},\n",
    "    {\"title\": \"Jogging\", \"tags\": [\"outdoor\", \"exercise\"]},\n",
    "    {\"title\": \"Team meeting\", \"tags\": [\"work\"]},\n",
    "]\n",
    "with open('tasks.json', 'w') as file:\n",
    "    json.dump(sample_tasks, file)\n",
    "\n",
    "input_text = \"Manage my tasks for today. Check if I can go jogging, and schedule my team meeting.\"\n",
    "\n",
    "# Plan and execute the tasks\n",
    "result = agent(input_text)\n",
    "\n",
    "# Display the result\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Built-in Tools for Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to search for the cricket or football match today first.\n",
      "Action: web_search\n",
      "Action Input: \"cricket match today\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mFind live score, updates and news for today's cricket matches on ESPNcricinfo. Follow the ICC men's T20 World Cup 2024, The Hundred, One-Day Cup, Shpageeza Cricket League and more. Get Live Cricket Scores, Ball By Ball Commentary, Latest Cricket and Scorecard Updates of all International and domestic cricket matches & related News. ... Today, 06:30 PM . notify. Find out the dates, times and venues of all the cricket matches happening around the world. Check the live scores, results and standings of international, domestic and youth cricket events. Mohammed Shami took a record five-for as India bowled out Sri Lanka for 55, their lowest ODI score, at Wankhede. India qualified for the semi-finals with seven wins in seven matches, while Sri Lanka faced elimination. Cricket Schedule. International Domestic & Others T20 Leagues Women All Matches. TUE, SEP 03 2024. ICC Mens T20 World Cup Asia Qualifier A 2024. Hong Kong vs Maldives, 10th Match. YSD-UKM Cricket ...\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI need to search for football matches today as well to see if there's a match.\n",
      "Action: web_search\n",
      "Action Input: \"football match today\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mFind out the scores and standings of all the football matches played today around the world. Watch live streams, highlights and stats of Premier League, LaLiga, Serie A, Ligue 1 and more. BeSoccer is your ultimate source for live soccer scores, news, stats and more. Follow all the action from the world's top leagues, tournaments and clubs with BeSoccer. Whether you are a fan of the Club World Cup, the Primera División or the Betis, you will find everything you need to know at BeSoccer. Find out the latest results of all today's football matches from various competitions around the world. See the scores, goals, standings and statistics of each game on BeSoccer. Find out the live soccer matches on TV and online for today and upcoming dates. See the schedules, scores, channels and streaming options for various leagues and competitions around the world. You can also watch football on TV from League One, League Two and the National League. Check below for times and channels. Time. Fixture. League/Competition. TV/Stream. 02:00. Brazil vs Ecuador ...\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI need to schedule a meeting since there are no cricket or football matches today.\n",
      "Action: add_to_calendar\n",
      "Action Input: \"Schedule meeting\"\u001b[0mAdding task to calendar: Schedule meeting\n",
      "\n",
      "Observation: \u001b[33;1m\u001b[1;3mTask Schedule meeting added to calendar.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know that there are no cricket or football matches today.\n",
      "Final Answer: There are no cricket or football matches today.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': 'Search for the cricket or football match today. if there is a match then displays the match details otherwise schedule a meeting', 'output': 'There are no cricket or football matches today.'}\n"
     ]
    }
   ],
   "source": [
    "# calculator Tool\n",
    "from langchain.agents import initialize_agent, Tool\n",
    "from langchain.tools import DuckDuckGoSearchRun\n",
    "\n",
    "# Initialize the DuckDuckGoSearchRun tool\n",
    "duckduckgo_tool = DuckDuckGoSearchRun()\n",
    "\n",
    "# Define a tool for performing a web search\n",
    "def perform_web_search(query):\n",
    "    try:\n",
    "        search_results = duckduckgo_tool.run(query)\n",
    "        return search_results\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "    \n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"web_search\",\n",
    "        func=perform_web_search,\n",
    "        description=\"Performs a web search using DuckDuckGo\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"add_to_calendar\",\n",
    "        func=add_to_calendar,\n",
    "        description=\"Adds a task to the calendar\"\n",
    "    )\n",
    "]\n",
    "\n",
    "agent = initialize_agent(tools, llm, agent=\"zero-shot-react-description\", verbose=True)\n",
    "\n",
    "# Input for the agent\n",
    "input_text = \"Search for the cricket or football match today. if there is a match then displays the match details otherwise schedule a meeting\"\n",
    "\n",
    "# Plan and execute the task\n",
    "result = agent(input_text)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chains & Memory\n",
    "\n",
    "- Large Language Models are stateless.\n",
    "- Each transaction is independent\n",
    "- Chatbots appear to have memory by providing the full conversation as context\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLM Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'product': 'Football', 'text': 'Touchdown Technologies'}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.9)\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"What is the best name to describe a company that makes {product}\"\n",
    ")\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "product = \"Football\"\n",
    "\n",
    "chain.invoke(product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'product': 'Football', 'text': '\"Touchdown Sports Co.\"'}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'product': 'Softwares', 'text': 'TechSolutions Software Co.'}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product  = \"Softwares\"\n",
    "chain.invoke(product)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LCEL (Langchain Expression Language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: Hi, I need help with my account.\n",
      "Response: Of course! I'd be happy to help you with your account. What specifically do you need assistance with? \n",
      "\n",
      "Input: I forgot my password.\n",
      "Response: I can help you reset your password. Please provide me with your account information so I can assist you further. \n",
      "\n",
      "Input: Can you help me reset it?\n",
      "Response: AI: Sure, I can help you reset your password. To do so, please provide me with your account username or email address so I can assist you further. \n",
      "\n",
      "Input: username: arslanhaider95\n",
      "Response: I'm sorry, but I am unable to assist with resetting passwords. Please contact your account provider for help with this issue. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", output_key=\"response\")\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"user_input\", \"history\"],\n",
    "    template=\"You are a helpful assistant. You have the following conversation history: {history}. Respond to the user's input: {user_input}\"\n",
    ")\n",
    "\n",
    "chain = prompt | llm\n",
    "\n",
    "user_inputs = [\n",
    "    \"Hi, I need help with my account.\",\n",
    "    \"I forgot my password.\",\n",
    "    \"Can you help me reset it?\",\n",
    "    \"username: arslanhaider95\"\n",
    "]\n",
    "\n",
    "for user_input in user_inputs:\n",
    "    response = chain.invoke({\"user_input\": user_input, \"history\": memory.load_memory_variables({}).get(\"chat_history\", \"\")})\n",
    "    print(\"Input:\", user_input)\n",
    "    print(\"Response:\", response.content + \" \\n\")\n",
    "    memory.save_context({\"user_input\": user_input}, {\"response\": []})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Complete Conversation History:\n",
      "\n",
      "Human: Hi, I need help with my account.\n",
      "AI: []\n",
      "Human: I forgot my password.\n",
      "AI: []\n",
      "Human: Can you help me reset it?\n",
      "AI: []\n",
      "Human: username: arslanhaider95\n",
      "AI: []\n"
     ]
    }
   ],
   "source": [
    "# Display the entire conversation history\n",
    "print(\"\\nComplete Conversation History:\\n\")\n",
    "print(memory.load_memory_variables({})[\"chat_history\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversation Buffer Memory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arslanhaider/.local/share/virtualenvs/generative-ai-cfm5DT86/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n",
      "/home/arslanhaider/.local/share/virtualenvs/generative-ai-cfm5DT86/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The class `ConversationChain` was deprecated in LangChain 0.2.7 and will be removed in 1.0. Use RunnableWithMessageHistory: https://api.python.langchain.com/en/latest/runnables/langchain_core.runnables.history.RunnableWithMessageHistory.html instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.0)\n",
    "\n",
    "memory = ConversationBufferMemory()\n",
    "\n",
    "conversation = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory=memory,\n",
    "    verbose=False,  # used to print the logs and other information during query execution\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello Arslan! It's nice to meet you. How can I assist you today?\""
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Hi, My name is Arslan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1 + 1 equals 2. Is there anything else you would like to know?'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What is 1 + 1?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your name is Arslan.'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What is my name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Hi, My name is Arslan\n",
      "AI: Hello Arslan! It's nice to meet you. How can I assist you today?\n",
      "Human: What is 1 + 1?\n",
      "AI: 1 + 1 equals 2. Is there anything else you would like to know?\n",
      "Human: What is my name?\n",
      "AI: Your name is Arslan.\n"
     ]
    }
   ],
   "source": [
    "print(memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': \"Human: Hi, My name is Arslan\\nAI: Hello Arslan! It's nice to meet you. How can I assist you today?\\nHuman: What is 1 + 1?\\nAI: 1 + 1 equals 2. Is there anything else you would like to know?\\nHuman: What is my name?\\nAI: Your name is Arslan.\"}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversation Token Buffer Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationTokenBufferMemory\n",
    "\n",
    "memory = ConversationTokenBufferMemory(llm=llm, max_token_limit=50)\n",
    "\n",
    "memory.save_context({\"input\": \"AI is what?!\"}, {\"output\": \"Amazing!\"})\n",
    "memory.save_context({\"input\": \"Backpropagation is what?!\"}, {\"output\": \"Wonderful!\"})\n",
    "memory.save_context({\"input\": \"Chatbots are what?!\"}, {\"output\": \"Charming!\"})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': \"Human: Hello\\nAI: What's Up?\\nHuman: Not much just hanging\\nAI: Cool\\nHuman: What is on the schedule today?\\nAI: Please schedule a meeting at 8:00 AM tomorrow with John Doe, Jane Smith, and Michael Johnson to discuss the upcoming project launch. Include the agenda in the invite and ensure all participants receive it. Also, create a presentation for the meeting that covers the project timeline, key milestones, team responsibilities,and any potential challenges we need to address.\\nHuman: What would be a good demo to show?\\nAI: A good demo to show would be a live demonstration of the project management software we will be using for the upcoming project. This will give the team a hands-on experience of how the software works and how it can help streamline our project processes. Additionally, you could also demonstrate a prototype of the project deliverable to give everyone a visual representation of what the end product will look like.\"}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})  # output with max_token_limit = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'AI: Wonderful!\\nHuman: Chatbots are what?!\\nAI: Charming!'}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})  # output with max_token_limit = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversation Summary Buffer Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "\n",
    "schedule = \"Please schedule a meeting at 8:00 AM tomorrow with John Doe, Jane Smith, and Michael Johnson to discuss the \\\n",
    "upcoming project launch. Include the agenda in the invite and ensure all participants receive it. Also, create a presentation \\\n",
    "for the meeting that covers the project timeline, key milestones, team responsibilities,\\\n",
    "and any potential challenges we need to address.\\\n",
    "\"\n",
    "\n",
    "memory = ConversationSummaryBufferMemory(llm=llm, max_token_limit=400)\n",
    "\n",
    "\n",
    "memory.save_context({\"input\": \"Hello\"}, {\"output\": \"What's Up?\"})\n",
    "memory.save_context({\"input\": \"Not much just hanging\"}, {\"output\": \"Cool\"})\n",
    "memory.save_context({\"input\": \"What is on the schedule today?\"}, {\"output\": f\"{schedule}\"})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': \"Human: Hello\\nAI: What's Up?\\nHuman: Not much just hanging\\nAI: Cool\\nHuman: What is on the schedule today?\\nAI: Please schedule a meeting at 8:00 AM tomorrow with John Doe, Jane Smith, and Michael Johnson to discuss the upcoming project launch. Include the agenda in the invite and ensure all participants receive it. Also, create a presentation for the meeting that covers the project timeline, key milestones, team responsibilities,and any potential challenges we need to address.\"}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hello\n",
      "AI: What's Up?\n",
      "Human: Not much just hanging\n",
      "AI: Cool\n",
      "Human: What is on the schedule today?\n",
      "AI: Please schedule a meeting at 8:00 AM tomorrow with John Doe, Jane Smith, and Michael Johnson to discuss the upcoming project launch. Include the agenda in the invite and ensure all participants receive it. Also, create a presentation for the meeting that covers the project timeline, key milestones, team responsibilities,and any potential challenges we need to address.\n",
      "Human: What would be a good demo to show?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'A good demo to show would be a live demonstration of the project management software we will be using for the upcoming project. This will give the team a hands-on experience of how the software works and how it can help streamline our project processes. Additionally, you could also demonstrate a prototype of the project deliverable to give everyone a visual representation of what the end product will look like.'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation = ConversationChain(llm=llm, memory=memory, verbose=True)\n",
    "\n",
    "conversation.predict(input=\"What would be a good demo to show?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': \"Human: Hello\\nAI: What's Up?\\nHuman: Not much just hanging\\nAI: Cool\\nHuman: What is on the schedule today?\\nAI: Please schedule a meeting at 8:00 AM tomorrow with John Doe, Jane Smith, and Michael Johnson to discuss the upcoming project launch. Include the agenda in the invite and ensure all participants receive it. Also, create a presentation for the meeting that covers the project timeline, key milestones, team responsibilities,and any potential challenges we need to address.\\nHuman: What would be a good demo to show?\\nAI: A good demo to show would be a live demonstration of the project management software we will be using for the upcoming project. This will give the team a hands-on experience of how the software works and how it can help streamline our project processes. Additionally, you could also demonstrate a prototype of the project deliverable to give everyone a visual representation of what the end product will look like.\"}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
