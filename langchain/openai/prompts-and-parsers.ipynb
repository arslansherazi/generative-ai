{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Great Wall of China\n",
      "2. Petra, Jordan\n",
      "3. Christ the Redeemer, Brazil\n",
      "4. Machu Picchu, Peru\n",
      "5. Chichen Itza, Mexico\n",
      "6. Colosseum, Italy\n",
      "7. Taj Mahal, India\n",
      "8. Great Pyramid of Giza, Egypt\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema import HumanMessage\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "\n",
    "messages = [\n",
    "    HumanMessage(content=\"List 8 wonders of the word\")\n",
    "]\n",
    "\n",
    "result = llm.invoke(messages)\n",
    "\n",
    "wonders_list = result.content.split(\"\\n\")\n",
    "\n",
    "for wonder in wonders_list:\n",
    "    print(wonder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Streaming and Batching\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1\n",
      ".\n",
      " Great\n",
      " Wall\n",
      " of\n",
      " China\n",
      "\n",
      "\n",
      "2\n",
      ".\n",
      " Petra\n",
      ",\n",
      " Jordan\n",
      "\n",
      "\n",
      "3\n",
      ".\n",
      " Christ\n",
      " the\n",
      " Rede\n",
      "emer\n",
      " statue\n",
      " in\n",
      " Rio\n",
      " de\n",
      " Janeiro\n",
      ",\n",
      " Brazil\n",
      "\n",
      "\n",
      "4\n",
      ".\n",
      " Mach\n",
      "u\n",
      " Pic\n",
      "chu\n",
      ",\n",
      " Peru\n",
      "\n",
      "\n",
      "5\n",
      ".\n",
      " Taj\n",
      " Mah\n",
      "al\n",
      ",\n",
      " India\n",
      "\n",
      "\n",
      "6\n",
      ".\n",
      " Col\n",
      "os\n",
      "se\n",
      "um\n",
      " in\n",
      " Rome\n",
      ",\n",
      " Italy\n",
      "\n",
      "\n",
      "7\n",
      ".\n",
      " Ch\n",
      "ichen\n",
      " It\n",
      "za\n",
      ",\n",
      " Mexico\n",
      "\n",
      "\n",
      "8\n",
      ".\n",
      " Pyramid\n",
      " of\n",
      " G\n",
      "iza\n",
      ",\n",
      " Egypt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for chunk in llm.stream(\"8 Wonders of World\"):\n",
    "    print(chunk.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 + 2 = 4\n",
      "58.68\n"
     ]
    }
   ],
   "source": [
    "result = llm.batch(\n",
    "    [\n",
    "        \"What's 2 +2 ?\",\n",
    "        \"What's 34.9 + 23.78?\"\n",
    "    ]\n",
    ")\n",
    "for _result in result:\n",
    "    print(_result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## System & Human Message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I am associated with the cricket bat manufacturer, MRF.'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.schema import SystemMessage\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are Virat Kohli\"),\n",
    "    HumanMessage(content=\"Which crickrt bat manufacturer you are associated with?\")\n",
    "]\n",
    "\n",
    "result = llm.invoke(messages)\n",
    "result.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Why did the robot go on a diet?\\n\\nBecause he had a byte problem!'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "    \"tell me a {objective} joke about {content}\"\n",
    ")\n",
    "\n",
    "filled_prompt = prompt_template.format(objective=\"funny\", content=\"robots\")\n",
    "\n",
    "response = llm.invoke(filled_prompt)\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chat Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a helpful AI Mathematics teacher bot. Your name is {name}\n",
      "Hello, How are you doing?\n",
      "I'm doing well, thanks!\n",
      "{math_problem}\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage\n",
    "\n",
    "# Defining a chat template with various roles\n",
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessage(content=\"You are a helpful AI Mathematics teacher bot. Your name is {name}\"),\n",
    "        HumanMessage(content=\"Hello, How are you doing?\"),\n",
    "        AIMessage(content=\"I'm doing well, thanks!\"),\n",
    "        HumanMessage(content=\"{math_problem}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "math_problem = input(\"Enter Math problem:\")\n",
    "\n",
    "formatted_messages = chat_template.format_messages(name=\"Bob\", math_problem=math_problem)\n",
    "\n",
    "for message in formatted_messages:\n",
    "    print(message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output Parsers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Json Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'birth_place': {'Elon Musk': 'Pretoria, South Africa',\n",
       "  'Bill Gates': 'Seattle, Washington, United States'},\n",
       " 'birth_date': {'Elon Musk': 'June 28, 1971',\n",
       "  'Bill Gates': 'October 28, 1955'}}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.output_parsers.json import SimpleJsonOutputParser\n",
    "\n",
    "json_parser = SimpleJsonOutputParser()\n",
    "\n",
    "template = \"\"\"\n",
    "Answer the user's question:\n",
    "{question}\n",
    "Return the answer as a JSON object with keys 'birth_place' and 'birth_date'.\n",
    "\"\"\"\n",
    "\n",
    "json_prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "json_chain = json_prompt | llm | json_parser\n",
    "\n",
    "input_data = {\"question\": \"When and where were Elon Musk and Bill Gates born?\"}\n",
    "\n",
    "output = json_chain.invoke(input_data)\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSV Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Afghanistan',\n",
       " 'Kabul',\n",
       " '1919\\nBahrain',\n",
       " 'Manama',\n",
       " '1971\\nBangladesh',\n",
       " 'Dhaka',\n",
       " '1971\\nBhutan',\n",
       " 'Thimphu',\n",
       " '1949\\nBrunei',\n",
       " 'Bandar Seri Begawan',\n",
       " '1984\\nCambodia',\n",
       " 'Phnom Penh',\n",
       " '1953\\nChina',\n",
       " 'Beijing',\n",
       " '1949\\nIndia',\n",
       " 'New Delhi',\n",
       " '1947\\nIndonesia',\n",
       " 'Jakarta',\n",
       " '1945\\nIran',\n",
       " 'Tehran',\n",
       " '1935\\nIraq',\n",
       " 'Baghdad',\n",
       " '1932\\nIsrael',\n",
       " 'Jerusalem',\n",
       " '1948\\nJapan',\n",
       " 'Tokyo',\n",
       " '660 BC\\nJordan',\n",
       " 'Amman',\n",
       " '1946\\nKazakhstan',\n",
       " 'Nur-Sultan',\n",
       " '1991\\nKuwait',\n",
       " 'Kuwait City',\n",
       " '1961\\nKyrgyzstan',\n",
       " 'Bishkek',\n",
       " '1991\\nLaos',\n",
       " 'Vientiane',\n",
       " '1949\\nLebanon',\n",
       " 'Beirut',\n",
       " '1943\\nMalaysia',\n",
       " 'Kuala Lumpur',\n",
       " '1957\\nMaldives',\n",
       " 'Mal√©',\n",
       " '1965\\nMongolia',\n",
       " 'Ulaanbaatar',\n",
       " '1921\\nMyanmar',\n",
       " 'Naypyidaw',\n",
       " '1948\\nNepal',\n",
       " 'Kathmandu',\n",
       " '1768\\nNorth Korea',\n",
       " 'Pyongyang',\n",
       " '1948\\nOman',\n",
       " 'Muscat',\n",
       " '1650\\nPakistan',\n",
       " 'Islamabad',\n",
       " '1947\\nPalestine',\n",
       " 'East Jerusalem',\n",
       " '1988\\nPhilippines',\n",
       " 'Manila',\n",
       " '1898\\nQatar',\n",
       " 'Doha',\n",
       " '1971\\nSaudi Arabia',\n",
       " 'Riyadh',\n",
       " '1932\\nSingapore',\n",
       " 'Singapore',\n",
       " '1965\\nSouth Korea',\n",
       " 'Seoul',\n",
       " '1948\\nSri Lanka',\n",
       " 'Colombo',\n",
       " '1948\\nSyria',\n",
       " 'Damascus',\n",
       " '1946\\nTajikistan',\n",
       " 'Dushanbe',\n",
       " '1991\\nThailand',\n",
       " 'Bangkok',\n",
       " '1238\\nTimor-Leste',\n",
       " 'Dili',\n",
       " '2002\\nTurkey',\n",
       " 'Ankara',\n",
       " '1923\\nTurkmenistan',\n",
       " 'Ashgabat',\n",
       " '1991\\nUnited Arab Emirates',\n",
       " 'Abu Dhabi',\n",
       " '1971\\nUzbekistan',\n",
       " 'Tashkent',\n",
       " '1991\\nVietnam',\n",
       " 'Hanoi',\n",
       " '1945\\nYemen',\n",
       " 'Sanaa',\n",
       " '1918']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.output_parsers import CommaSeparatedListOutputParser\n",
    "\n",
    "csv_parser = CommaSeparatedListOutputParser()\n",
    "\n",
    "template = \"\"\"\n",
    "Answer the user's question:\n",
    "{question}\n",
    "Return the answer as a comma-separated list with the format: \"Country, Capital, Independence Date\".\n",
    "Only include countries in Asia.\n",
    "\"\"\"\n",
    "\n",
    "csv_prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "csv_chain = csv_prompt | llm | csv_parser\n",
    "\n",
    "input_data = {\"question\": \"Give details of countries in Aisa\"}\n",
    "\n",
    "output = csv_chain.invoke(input_data)\n",
    "output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
