{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LangGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.graph import StateGraph\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import HumanMessage\n",
    "\n",
    "def agent_one(state):\n",
    "    \"\"\"First agent that processes input and adds a step.\"\"\"\n",
    "    messages = [\n",
    "        HumanMessage(content=\"Summarize: \" + state.input)\n",
    "    ]   \n",
    "    response = llm.invoke(messages)  \n",
    "    state.summary = response.content\n",
    "    return state\n",
    "\n",
    "def agent_two(state):\n",
    "    \"\"\"Second agent that generates keywords from the summary.\"\"\"\n",
    "    messages = [\n",
    "        HumanMessage(content=\"Extract keywords: \" + state.summary)\n",
    "    ]  \n",
    "    response = llm.invoke(messages)\n",
    "    state.keywords = response.content\n",
    "    return state\n",
    "\n",
    "def agent_three(state):\n",
    "    \"\"\"Third agent that generates a final refined response.\"\"\"\n",
    "    messages = [\n",
    "        HumanMessage(content=\"Generate a short response using: \" + state.keywords)\n",
    "    ]\n",
    "    response = llm.invoke(messages)\n",
    "    state.final_response = response.content\n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Workflow (Nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "class State(BaseModel):\n",
    "    input: str\n",
    "    summary: str | None = None\n",
    "    keywords: str | None = None\n",
    "    final_response: str | None = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x11f74de20>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph = StateGraph(State)\n",
    "graph.add_node(\"AgentOne\", agent_one)\n",
    "graph.add_node(\"AgentTwo\", agent_two)\n",
    "graph.add_node(\"AgentThree\", agent_three)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x11f74de20>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.add_edge(\"AgentOne\", \"AgentTwo\")\n",
    "graph.add_edge(\"AgentTwo\", \"AgentThree\")\n",
    "\n",
    "graph.set_entry_point(\"AgentOne\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain streamlines the process of working with artificial intelligence by making it easier and more efficient.\n",
      "Keywords: LangChain, streamlines, process, working, artificial intelligence, easier, efficient.\n",
      "LangChain streamlines the process of working with artificial intelligence, making it easier and more efficient for users.\n"
     ]
    }
   ],
   "source": [
    "runnable_graph = graph.compile()\n",
    "\n",
    "initial_state = State(input=\"LangChain simplifies AI workflows.\")\n",
    "final_state = State(**runnable_graph.invoke(initial_state))\n",
    "\n",
    "print(final_state.summary)\n",
    "print(final_state.keywords)\n",
    "print(final_state.final_response)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "generative-ai-XwelIRLU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
