{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e999578",
   "metadata": {},
   "source": [
    "# Auto Gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1624d592",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import autogen\n",
    "from autogen import AssistantAgent, UserProxyAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "28a60e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "if not openai_api_key:\n",
    "    raise ValueError(\"Please set the OPENAI_API_KEY environment variable\")\n",
    "\n",
    "config_list = [{\n",
    "    \"model\": \"gpt-4\",\n",
    "    \"api_key\": openai_api_key\n",
    "}]\n",
    "\n",
    "llm_config = {\n",
    "    \"config_list\": config_list,\n",
    "    \"temperature\": 0.7,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bc8b2007",
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant = AssistantAgent(\n",
    "    name=\"AI_Assistant\",\n",
    "    llm_config=llm_config,\n",
    "    system_message=\"You are a helpful AI assistant with expertise in Python programming. \\\n",
    "                   Help the user solve programming tasks step by step.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "83720907",
   "metadata": {},
   "outputs": [],
   "source": [
    "executor = UserProxyAgent(\n",
    "    name=\"Code_Executor\",              # Identifies the agent in the conversation\n",
    "    human_input_mode=\"NEVER\",          # Prevents asking for human input during execution\n",
    "    is_termination_msg=lambda msg: \"TERMINATE\" in msg[\"content\"],  # Defines when to end the conversation\n",
    "    code_execution_config={            # Configuration for code execution capabilities\n",
    "        \"last_n_messages\": 3,          # Number of recent messages to consider for code execution\n",
    "        \"work_dir\": \"coding_workspace\",  # Directory where code will be executed and files saved\n",
    "        \"use_docker\": False,           # Whether to run code in a Docker container for isolation\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1d4f0f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "user = UserProxyAgent(\n",
    "    name=\"User\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    is_termination_msg=lambda msg: \"TERMINATE\" in msg[\"content\"],\n",
    "    code_execution_config=False,  # User won't execute code\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d1de0bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "groupchat = autogen.GroupChat(\n",
    "    agents=[user, assistant, executor],\n",
    "    messages=[],\n",
    "    max_round=12\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6bec470a",
   "metadata": {},
   "outputs": [],
   "source": [
    "manager = autogen.GroupChatManager(\n",
    "    groupchat=groupchat,\n",
    "    llm_config=llm_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9d169e25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mUser\u001b[0m (to chat_manager):\n",
      "\n",
      "I need to create a function that calculates the Fibonacci sequence up to n terms.             Then plot the sequence to visualize its growth.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: AI_Assistant\n",
      "\u001b[0m\n",
      "\u001b[33mAI_Assistant\u001b[0m (to chat_manager):\n",
      "\n",
      "Sure, I can help with that. Let's break down this task into two parts: calculating the Fibonacci sequence up to n terms, and then plotting the sequence.\n",
      "\n",
      "First, let's write a Python function to calculate the Fibonacci series up to n terms.\n",
      "\n",
      "```python\n",
      "def fibonacci(n):\n",
      "    fib_sequence = [0, 1]\n",
      "    while len(fib_sequence) < n:\n",
      "        fib_sequence.append(fib_sequence[-1] + fib_sequence[-2])\n",
      "    return fib_sequence\n",
      "```\n",
      "\n",
      "In this function, we start with a list that already contains the first two terms of the Fibonacci sequence: 0 and 1. Then, we enter a loop that continues until the list contains n terms. In each iteration of the loop, we append the sum of the last two terms of the sequence to the list.\n",
      "\n",
      "Now, let's create a function to plot the Fibonacci sequence using matplotlib.\n",
      "\n",
      "```python\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "def plot_fibonacci(n):\n",
      "    fib_sequence = fibonacci(n)\n",
      "    plt.plot(fib_sequence)\n",
      "    plt.title('Fibonacci Sequence')\n",
      "    plt.xlabel('Term')\n",
      "    plt.ylabel('Value')\n",
      "    plt.show()\n",
      "```\n",
      "\n",
      "In this function, we first calculate the Fibonacci sequence up to n terms. Then, we use matplotlib's `plot` function to generate a line graph of the sequence. The x-axis represents the term number in the sequence, and the y-axis represents the value of the term. Finally, `plt.show()` is called to display the plot.\n",
      "\n",
      "You can run `plot_fibonacci(n)` to generate a plot of the Fibonacci sequence up to n terms. For example, `plot_fibonacci(10)` will generate a plot of the first 10 terms of the Fibonacci sequence.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: Code_Executor\n",
      "\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> EXECUTING CODE BLOCK 0 (inferred language is python)...\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> EXECUTING CODE BLOCK 1 (inferred language is python)...\u001b[0m\n",
      "\u001b[33mCode_Executor\u001b[0m (to chat_manager):\n",
      "\n",
      "exitcode: 1 (execution failed)\n",
      "Code output: \n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"\", line 1, in <module>\n",
      "    import matplotlib.pyplot as plt\n",
      "ModuleNotFoundError: No module named 'matplotlib'\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: User\n",
      "\u001b[0m\n",
      "\u001b[33mUser\u001b[0m (to chat_manager):\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: User\n",
      "\u001b[0m\n",
      "\u001b[33mUser\u001b[0m (to chat_manager):\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: User\n",
      "\u001b[0m\n",
      "\u001b[33mUser\u001b[0m (to chat_manager):\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: User\n",
      "\u001b[0m\n",
      "\u001b[33mUser\u001b[0m (to chat_manager):\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: User\n",
      "\u001b[0m\n",
      "\u001b[33mUser\u001b[0m (to chat_manager):\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: User\n",
      "\u001b[0m\n",
      "\u001b[33mUser\u001b[0m (to chat_manager):\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: User\n",
      "\u001b[0m\n",
      "\u001b[33mUser\u001b[0m (to chat_manager):\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: User\n",
      "\u001b[0m\n",
      "\u001b[33mUser\u001b[0m (to chat_manager):\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: User\n",
      "\u001b[0m\n",
      "\u001b[33mUser\u001b[0m (to chat_manager):\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> TERMINATING RUN (c000a8e7-1a05-4d71-ba94-17dde8ef06a5): Maximum rounds (12) reached\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ChatResult(chat_id=None, chat_history=[{'content': 'I need to create a function that calculates the Fibonacci sequence up to n terms.             Then plot the sequence to visualize its growth.', 'role': 'assistant', 'name': 'User'}, {'content': \"Sure, I can help with that. Let's break down this task into two parts: calculating the Fibonacci sequence up to n terms, and then plotting the sequence.\\n\\nFirst, let's write a Python function to calculate the Fibonacci series up to n terms.\\n\\n```python\\ndef fibonacci(n):\\n    fib_sequence = [0, 1]\\n    while len(fib_sequence) < n:\\n        fib_sequence.append(fib_sequence[-1] + fib_sequence[-2])\\n    return fib_sequence\\n```\\n\\nIn this function, we start with a list that already contains the first two terms of the Fibonacci sequence: 0 and 1. Then, we enter a loop that continues until the list contains n terms. In each iteration of the loop, we append the sum of the last two terms of the sequence to the list.\\n\\nNow, let's create a function to plot the Fibonacci sequence using matplotlib.\\n\\n```python\\nimport matplotlib.pyplot as plt\\n\\ndef plot_fibonacci(n):\\n    fib_sequence = fibonacci(n)\\n    plt.plot(fib_sequence)\\n    plt.title('Fibonacci Sequence')\\n    plt.xlabel('Term')\\n    plt.ylabel('Value')\\n    plt.show()\\n```\\n\\nIn this function, we first calculate the Fibonacci sequence up to n terms. Then, we use matplotlib's `plot` function to generate a line graph of the sequence. The x-axis represents the term number in the sequence, and the y-axis represents the value of the term. Finally, `plt.show()` is called to display the plot.\\n\\nYou can run `plot_fibonacci(n)` to generate a plot of the Fibonacci sequence up to n terms. For example, `plot_fibonacci(10)` will generate a plot of the first 10 terms of the Fibonacci sequence.\", 'name': 'AI_Assistant', 'role': 'user'}, {'content': 'exitcode: 1 (execution failed)\\nCode output: \\n\\nTraceback (most recent call last):\\n  File \"\", line 1, in <module>\\n    import matplotlib.pyplot as plt\\nModuleNotFoundError: No module named \\'matplotlib\\'\\n', 'name': 'Code_Executor', 'role': 'user'}, {'content': '', 'role': 'assistant', 'name': 'User'}, {'content': '', 'role': 'assistant', 'name': 'User'}, {'content': '', 'role': 'assistant', 'name': 'User'}, {'content': '', 'role': 'assistant', 'name': 'User'}, {'content': '', 'role': 'assistant', 'name': 'User'}, {'content': '', 'role': 'assistant', 'name': 'User'}, {'content': '', 'role': 'assistant', 'name': 'User'}, {'content': '', 'role': 'assistant', 'name': 'User'}, {'content': '', 'role': 'assistant', 'name': 'User'}], summary='', cost={'usage_including_cached_inference': {'total_cost': 0}, 'usage_excluding_cached_inference': {'total_cost': 0}}, human_input=[])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user.initiate_chat(\n",
    "    manager,\n",
    "    message=\"I need to create a function that calculates the Fibonacci sequence up to n terms. \\\n",
    "            Then plot the sequence to visualize its growth.\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "generative-ai-XwelIRLU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
