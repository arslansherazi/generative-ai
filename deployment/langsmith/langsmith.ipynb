{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangSmith"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Great Wall of China\n",
      "2. Petra, Jordan\n",
      "3. Christ the Redeemer, Brazil\n",
      "4. Machu Picchu, Peru\n",
      "5. Chichen Itza, Mexico\n",
      "6. Taj Mahal, India\n",
      "7. Colosseum, Italy\n",
      "8. Great Pyramid of Giza, Egypt\n"
     ]
    }
   ],
   "source": [
    "from langsmith.wrappers import wrap_openai\n",
    "import openai\n",
    "from langsmith import traceable\n",
    "\n",
    "# Auto traceable decorator\n",
    "client = wrap_openai(openai.Client())\n",
    "\n",
    "@traceable\n",
    "def pipeline1(prompt):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "result = pipeline1(\"List 8 wonders of world\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Alfred Hitchcock\n",
      "2. Steven Spielberg\n",
      "3. Martin Scorsese\n",
      "4. Stanley Kubrick\n",
      "5. Quentin Tarantino\n",
      "6. Akira Kurosawa\n",
      "7. Francis Ford Coppola\n",
      "8. Christopher Nolan\n",
      "9. Ridley Scott\n",
      "10. Pedro Almod√≥var\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langsmith import traceable\n",
    "\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "@traceable(name=\"pipeline2\")\n",
    "def pipeline(user_input: str):\n",
    "    result = llm.invoke(user_input)\n",
    "    return result.content\n",
    "\n",
    "result = pipeline(\"List some top directors of all time\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Harrison worked at Kensho.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from langsmith.wrappers import wrap_openai\n",
    "\n",
    "openai_client = wrap_openai(OpenAI())\n",
    "\n",
    "def retriever(query: str):\n",
    "    results = [\"Harrison worked at Kensho\"]\n",
    "    return results\n",
    "\n",
    "def rag(question):\n",
    "    docs = retriever(question)\n",
    "    system_message = \"\"\"Answer the users question using only the provided information below:\n",
    "    \n",
    "    {docs}\"\"\".format(docs=\"\\n\".join(docs))\n",
    "    \n",
    "    return openai_client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_message},\n",
    "            {\"role\": \"user\", \"content\": question},\n",
    "        ],\n",
    "        model=\"gpt-4o-mini\",\n",
    "    )\n",
    "\n",
    "result = rag(\"What did Harrison do?\")\n",
    "print(result.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "generative-ai-XwelIRLU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
